ğŸŒŸ Hi, Iâ€™m Anal Roy Chowdhury

Researcher in Multimodal AI â€¢ Sign Language Processing â€¢ Medical Imaging â€¢ Multi-View Learning

â¸»

ğŸ‘‹ About Me

Iâ€™m a researcher working at the intersection of computer vision, natural language processing, and multimodal machine learning. My work focuses on building systems that are inclusive, accessible, and impactful, especially in communication and healthcare domains.

My recent research spans:
	â€¢	ğŸ¤Ÿ Sign Language Translation (SLT) â€” Indian Sign Language dataset curation, videoâ€“language modeling
	â€¢	ğŸï¸ Multimodal & Motion-Aware Models â€” vision-language models, temporal modeling, contrastive alignment
	â€¢	ğŸ§© Multi-View Clustering & Representation Learning
	â€¢	ğŸ©º Medical Image Analysis â€” segmentation, classification, multimodal fusion
	â€¢	âš¡ Efficient Training â€” LoRA/QLoRA, feature caching, GPU-optimized pipelines

â¸»

ğŸ”¬ Research Interests
	â€¢	Multimodal Machine Learning
	â€¢	Sign Language Processing
	â€¢	Videoâ€“Language Models
	â€¢	Multi-View Learning
	â€¢	Medical Imaging
	â€¢	Representation Learning
	â€¢	Low-bit / Efficient Fine-tuning

â¸»

ğŸ§ª Current Work
	â€¢	Building motion-aware videoâ€“language models for Indian Sign Language translation
	â€¢	Designing contrastive pretraining pipelines for aligning video and text embeddings
	â€¢	Curating high-quality datasets for SLT
	â€¢	Exploring efficient training strategies for large visionâ€“language models

â¸»

ğŸ› ï¸ Tech Stack

Languages:
Python Â· C Â· Shell

ML / DL Frameworks:
PyTorch Â· Hugging Face Transformers Â· Lightning Â· OpenCV Â· scikit-learn

Video / Vision Tools:
Decord Â· MMCV Â· FFmpeg

Other Tools:
WandB Â· tmux Â· LaTeX

# ğŸŒŸ Hi, Iâ€™m **Anal Roy Chowdhury**

### *Researcher in Multimodal AI â€¢ Sign Language Processing â€¢ Medical Imaging â€¢ Multi-View Learning*

---

## ğŸ‘‹ About Me

Iâ€™m a researcher working at the intersection of **computer vision**, **natural language processing**, and **multimodal machine learning**. My work focuses on building systems that are **inclusive, accessible, and impactful**, especially in communication and healthcare domains.

My recent research spans:

- ğŸ¤Ÿ **Sign Language Translation (SLT)** â€” Indian Sign Language dataset curation, videoâ€“language modeling  
- ğŸï¸ **Multimodal & Motion-Aware Models** â€” visionâ€“language models, temporal modeling, contrastive alignment  
- ğŸ§© **Multi-View Clustering & Representation Learning**  
- ğŸ©º **Medical Image Analysis** â€” segmentation, classification, multimodal fusion  
- âš¡ **Efficient Training** â€” LoRA/QLoRA, feature caching, GPU-optimized pipelines  

---

## ğŸ”¬ Research Interests

- Multimodal Machine Learning  
- Sign Language Processing  
- Videoâ€“Language Models  
- Multi-View Learning  
- Medical Imaging  
- Representation Learning  
- Low-bit / Efficient Fine-tuning  

---

## ğŸ§ª Current Work

- Building **motion-aware videoâ€“language models** for Indian Sign Language translation  
- Designing **contrastive pretraining pipelines** for aligning video and text embeddings  
- Curating **high-quality datasets** for SLT  
- Exploring **efficient training strategies** for large visionâ€“language models  

---

## ğŸ› ï¸ Tech Stack

### **Languages:**  
Python Â· C Â· Shell  

### **ML / DL Frameworks:**  
PyTorch Â· Hugging Face Transformers Â· Lightning Â· OpenCV Â· scikit-learn  

### **Video / Vision Tools:**  
Decord Â· MMCV Â· FFmpeg  

### **Other Tools:**  
WandB Â· tmux Â· LaTeX  
